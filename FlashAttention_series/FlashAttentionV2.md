##### FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning 

### 导读





[1] https://zhuanlan.zhihu.com/p/645376942

https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247519477&idx=1&sn=ee4fe0a47c7f517a9dda9976cc7075f7&chksm=9f833663a8f4bf7529c5d0b63f2ccabdf69ef2189a6e88b3ecadf7ecba3f79f66db4241eb6b8&scene=21#wechat_redirect

[2] https://blog.csdn.net/Taobaojishu/article/details/133366239?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-133366239-blog-133619540.235%5Ev40%5Epc_relevant_3m_sort_dl_base2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-133366239-blog-133619540.235%5Ev40%5Epc_relevant_3m_sort_dl_base2&utm_relevant_index=10













