##### FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness 

### 导读

#### 

不写了，直接两位大佬的博客。不可能写的更好了。剩下也许就是翻译原论文了。

[1] https://blog.csdn.net/v_JULY_v/article/details/133619540

[2] http://fancyerii.github.io/2023/10/23/flashattention/



图解：

[3] https://zhuanlan.zhihu.com/p/626079753

https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247519461&amp;idx=1&amp;sn=292e647dd10734e3ae8bfc00b7f0e645&amp;chksm=9f833673a8f4bf653718401443fb09e71f349dafc59df43260f13b284465e927eaf5a504bc0f&amp;scene=21#wechat_redirect

带有内存访问复杂度分析

[4] https://readpaper.feishu.cn/docx/AC7JdtLrhoKpgxxSRM8cfUounsh



















