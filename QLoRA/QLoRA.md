##### QLoRA



1. 尽管 LLM 训练（或者一般在 GPU 上训练模型时）具有固有的随机性，但多次运行的结果仍然非常一致。
2. 如果您受到 GPU 内存的限制，QLoRA 提供的权衡可能是值得的。它节省了33% 的内存，但运行时间增加了39%。

QLoRA 是由 Tim Dettmers 等人提出的量化 LoRA 的缩写。QLoRA 是一种在微调过程中进一步减少内存占用的技术。在反向传播过程中，QLoRA 将预训练的权重量化为 4-bit，并使用分页优化器来处理内存峰值。

使用LoRA时可以节省33%的GPU内存。然而，由于QLoRA中预训练模型权重的额外量化和去量化，训练时间增加了39%。

默认LoRA具有16bit浮点精度：

训练时长：1.85 小时
内存占用：21.33GB
具有4位正常浮点数的 QLoRA

训练时长为：2.79h
内存占用为：14.18GB



QLoRA创新点：

基础知识：

量化是将高精度数值用低精度数值表示的方法；如fp32->int8，将源数据每个值除以一个绝对值最大值、乘以目标数据的最大值，因此存在一个高精度缩放系数，用于进行反量化；

由于存在异常值，会影响量化精度，所以量化一般都是分块进行的。将数据分成N份，分别对每份进行量化，这样每份数据就有一个量化系数。

1）NF4量化，节省显存、精度损失小；

简单粗暴的理解。量化时进行分块虽然降低了降低了精度损失，但是每块中的数值仍然可能分布不均衡。因此NF4的想法就是强行均衡。将数据按大小排序，然后再分块。这样大小连续的数据在一个块内进行量化，基本避免了异常值存在，且数据较为均衡。

就是所谓的分位数量化，信息论最优。

分位数量化（Quantile Quantization）是隶属于非线性量化。. 分位数 （Quantile）在数学上的定义指的是把 顺序排列 的一组数据分割为若干个相等块的分割 …

2）Double Quantizition，双量化，量化量化参数，进一步节省显存；

量化是将高精度数值用低精度数值表示的方法；如fp32->int8，将源数据每个值除以一个绝对值最大值、乘以目标数据的最大值，因此存在一个高精度缩放系数，用于进行反量化；

由于存在异常值，会影响量化精度，所以量化一般都是分块进行的。将数据分成N份，分别对每份进行量化，这样每份数据就有一个量化系数。

假设第一次量化时每份数据包含64个参数，需要一个fp32的量化系数，那么平均每个参数多占用为32/64=0.5bit。

第二次量化，量化的是上一步生成的fp32的量化系数，由于每块数据仅有一个系数，因此第二次量化实际上包含了很多块原始数据，需要注意理解。

假设第二次量化时每份数据为256个参数，且将每个参数量化为FP8，每块需要一个fp32的量化系数。因此双量化就是把fp32的量化系数再量化成FP8，同时再生成一个fp32的量化系数。这时每个参数增加的占用就是8/64+32/(64*256)。

8/64：表示第一次量化时，每64个数据对应的量化系数，在第二次量化时把它量化成了FP8；

32/(64*256)：32表示第二次量化时每块数据的量化系数，但是第二次量化的这个系数对应了原始参数的数量变成了64\*256个。因为第一次是64个数据只生成一个量化系数，而第二次量化是每256个数一起量化，才生成一个量化系数，这256个数的每一个都对应了第一次量化的64个参数，所以第二次量化的系数对应了64\*256个原始参数。

**注意不是每个权重值量化所需要的空间，而是所需要的额外空间。**

3）Paged Optimizers，内存统一管理，避免activation checkpoint时的内存峰值爆显存；

其实就是快爆时卸载到CPU一部分暂时不用的优化器参数；

这种技术利用了NVIDIA统一内存的特性，实现了CPU和GPU之间自动的页面转换。当GPU内存不足时，Paged Optimizers技术会自动将优化器状态转移到CPU内存，以确保优化器的正常运行。
Paged Optimizers：分页优化器，是一种能够在CPU和GPU之间自动转换优化器状态的技术。
NVIDIA统一内存：一种将CPU和GPU内存统一管理的技术，可以让CPU和GPU共享同一块内存，从而减少数据传输的时间和开销。

4）**增加Adapter**：4-bit的NormalFloat与Double Quantization，节省了很多空间，但带来了性能损失，作者通过插入更多adapter来弥补这种性能损失。在LoRA中，一般会选择在query和value的全连接层处插入adapter。而QLoRA则在所有全连接层处都插入了adapter，增加了训练参数，弥补精度带来的性能损失。





QLoRA+more adapter，由于Lora效果，因此微调更多的参数对提升精度的影响较大，r的值影响较小；

QLoRA精度几乎无损，达到LoRA甚至full fp16的精度；

1）QLoRA是量化后微调，相较于微调后量化精度损失更小；

2）量化节省显存，可以扩大adapter数量，微调更多的参数，提升指标；

3）NF4是信息论最优方法，量化精度本身就比int4高；



【参考】https://cloud.tencent.com/developer/article/2375230



https://blog.csdn.net/HERODING23/article/details/131584089

https://blog.csdn.net/qq_16949707/article/details/131024256

NF4量化详解

https://zhuanlan.zhihu.com/p/666234324

https://zhuanlan.zhihu.com/p/654967425

思维盗图

https://zhuanlan.zhihu.com/p/635345199

















