##### LoRA

大模型微调使用的一种技术叫参数高效微调技术，Parameter-Efficient Fine-Tuning，其中一种流行的方法就是LoRA。

低秩适应（Low-Rank Adaptation）是一种参数高效的微调方法，其核心思想是对大型模型的权重矩阵进行隐式的低秩转换。

为了让大模型微调的成本「打下来」，微软的研究人员开发了低秩自适应（LoRA）技术。LoRA 的精妙之处在于，它相当于在原有大模型的基础上增加了一个可拆卸的插件，模型主体保持不变。LoRA 随插随用，轻巧方便。



由Edward Hu等人提出的LoRA将权重变化$\nabla W$分解为一个低秩表示。确切地说，LoRA并不直接对权重矩阵进行分解，而是通过反向传播学习分解后的矩阵表示。

直观推导。在正常的微调训练过程中，权重$\nabla W$的变换如下：

假设$W$表示网络层中的权重矩阵。通过反向传播我们可以得到权重的更新为$\nabla W$。

通常计算方法为损失的负梯度再乘以学习率：
$$
\nabla W = \alpha (-\nabla L_W)
$$
然后通过下面的式子更新原始权重$W$:
$$
W^{'}=W+\nabla W
$$
为了方便理解LoRA的思想，我们将权重更新矩阵$\nabla W $和原始$W$保持分开展示，并按照以下方式计算输出：
$$
h=(W+\nabla W)x  \\
h=Wx+\nabla Wx
$$
LoRA学习的就是$\nabla W$，将其分解为两个矩阵相乘的形式，也就是其低秩表示，每次更新都是更新两个低秩矩阵而保持原权重不变。

在深度学习中，权重矩阵通常具有完整秩也称满秩（full rank）。完整秩是一个技术术语，意味着权重矩阵的行或列之间没有线性相关（即“冗余”）关系，也就是说每个权重在模型中承担了不同的作用，没有冗余。这种情况下，权重矩阵能够充分表达模型的复杂性和丰富的特征表示能力。权重矩阵具有完整秩的好处是，模型可以通过学习到的权重进行准确的预测和分类。每个权重都对模型的输出产生影响，而且没有多余的冗余信息。

相反与完整秩相对应，低秩意味着矩阵具有冗余的行或列。

某些情况下，完整秩的权重矩阵可能会导致一些问题。例如，当训练数据量较少或数据噪声较多时，权重矩阵可能会过拟合，导致模型泛化能力下降。此外，权重矩阵中的大量参数可能会导致计算和存储的开销很大。
因此，在一些参数效率方面的研究中，人们开始关注如何利用低秩矩阵来表示权重矩阵。通过使用低秩矩阵，我们可以降低参数的数量，减少计算和存储的开销，并且仍然保留了大部分原始权重矩阵的关键信息。这样，我们可以在保持模型性能的同时，提高计算效率和模型的可解释性。

虽然预训练模型的权重在预训练任务中具有完整秩，但LoRA的作者指出，当预训练的大型语言模型适应新任务时，其固有维度很低，这是根据Aghajanyan等人的研究（2020）得出的。（换句话说：实际微调后的权重其实对比原始模型，能用到的权重其实很少）。

低秩维度意味着数据可以通过较低维度的空间有效表示或近似，同时保留其大部分重要信息或结构。换句话说，这意味着我们可以将适应任务的新权重矩阵分解为较低维度（较小）的矩阵，而不会丢失太多重要信息。

当然，分解表示的矩阵A和B无法捕捉到涵盖的所有信息，但这是LoRA的设计所决定的。在使用LoRA时，我们假设模型是一个具有全秩的大矩阵，以收集预训练数据集中的所有知识。当微调LLM 时，不需要更新所有权重，只需要更新较少的权重来捕捉核心信息，低秩更新就是这么通过矩阵实现的。

LoRA 的实现原理，其实现流程为：

在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；

用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B ；

训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数。




关于和这两个低秩矩阵的初始化问题，首先我们是需要的结果初始是0，这样就能保证微调开始时新引入的低秩矩阵不会对最终结果造成影响，那么最直接的方式就是令其中一个低秩矩阵初始阶段为全零，另一个为非全零即可。但是两者不能都为全零，如果这两个低秩矩阵初始化都是全0，那么两个矩阵的梯度都是0，也就训不起来。

详细解释：

如果A和B都初始化为0，前向传播时A的权重为0，无论输入是什么，输出都为0。A的输出就是B的输入，因此B的输入为0，且权重为0，输出也是0。

反向传播时，由于B的权重和输入都是0，使得B的权重梯度为0，B矩阵将不会被更新，而B的输入的梯度也是0，因此A传到A时的梯度为0，所以A的权重梯度也是0，A矩阵也不会被更新，A的输入梯度也是0，从A继续回传也就没有意义。所以整体上新加入的低秩矩阵的训练将毫无意义。



低秩矩阵

一个矩阵可以拆分为由两个矩阵相乘得到，则称之为低秩可分解矩阵；

满秩：矩阵行列式每一行或列互不相关，也就是每一行或列都不能通过其他行或列进行基本运算而得到；



【参考】

https://developer.aliyun.com/article/1257855

https://cloud.tencent.com/developer/article/2372297

https://blog.csdn.net/qjzcy/article/details/131206691

https://developer.aliyun.com/article/1257855

https://blog.csdn.net/weixin_44826203/article/details/129733930

https://cloud.tencent.com/developer/article/2375230